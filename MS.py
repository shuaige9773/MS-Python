import os
import cv2
import numpy as np
import pywt
import tkinter as tk
from tkinter import filedialog, ttk, Scale, HORIZONTAL, Scrollbar, messagebox
from PIL import Image, ImageTk
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import platform
from concurrent.futures import ThreadPoolExecutor
import threading
from functools import lru_cache
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from skimage.metrics import structural_similarity as ssim
import glob
import time

# ===================== æ·±åº¦å­¦ä¹ æ¨¡å‹å®šä¹‰ =====================

class SEBlock(nn.Module):
    """Squeeze-and-Excitationå—ï¼Œç”¨äºæ³¢æ®µæ³¨æ„åŠ›"""
    def __init__(self, channels, reduction=16):
        super(SEBlock, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class ResidualBlock(nn.Module):
    """æ®‹å·®å—"""
    def __init__(self, channels, use_se=True):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(channels)
        self.se = SEBlock(channels) if use_se else None
    
    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.se:
            out = self.se(out)
        out += residual
        return self.relu(out)

class MSResNet(nn.Module):
    """å¤šå…‰è°±æ®‹å·®ç½‘ç»œ"""
    def __init__(self, in_channels=3, out_channels=3, num_features=64, num_blocks=5):
        super(MSResNet, self).__init__()
        
        # åˆå§‹å·ç§¯å±‚
        self.conv_in = nn.Conv2d(in_channels, num_features, 3, padding=1)
        
        # æ®‹å·®å—
        self.res_blocks = nn.Sequential(
            *[ResidualBlock(num_features, use_se=True) for _ in range(num_blocks)]
        )
        
        # è¾“å‡ºå·ç§¯å±‚
        self.conv_out = nn.Conv2d(num_features, out_channels, 3, padding=1)
    
    def forward(self, x):
        # æ®‹å·®å­¦ä¹ ï¼šé¢„æµ‹å™ªå£°
        out = self.conv_in(x)
        out = self.res_blocks(out)
        noise = self.conv_out(out)
        return x - noise  # è¿”å›å»å™ªåçš„å›¾åƒ

class SPPBlock(nn.Module):
    """å…‰è°±é‡‘å­—å¡”æ± åŒ–å—"""
    def __init__(self, in_channels, pool_sizes=[1, 2, 4]):
        super(SPPBlock, self).__init__()
        self.pool_sizes = pool_sizes
        self.pools = nn.ModuleList([
            nn.AdaptiveAvgPool2d(size) for size in pool_sizes
        ])
        # è¾“å‡ºé€šé“æ•° = è¾“å…¥é€šé“æ•° * æ± åŒ–å°ºå¯¸æ•°é‡
        out_channels = in_channels * len(pool_sizes)
        self.conv = nn.Conv2d(out_channels, in_channels, 1)
    
    def forward(self, x):
        features = []
        for pool in self.pools:
            pooled = pool(x)
            # ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
            upsampled = nn.functional.interpolate(
                pooled, size=x.shape[2:], mode='bilinear', align_corners=False
            )
            features.append(upsampled)
        
        # æ‹¼æ¥æ‰€æœ‰å°ºåº¦çš„ç‰¹å¾
        out = torch.cat(features, dim=1)
        out = self.conv(out)
        return out

class DAE_SPP(nn.Module):
    """åŸºäºU-Netçš„å»å™ªè‡ªç¼–ç å™¨with SPP"""
    def __init__(self, in_channels=3, out_channels=3, features=[64, 128, 256, 512]):
        super(DAE_SPP, self).__init__()
        
        self.encoder = nn.ModuleList()
        self.decoder = nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # ç¼–ç å™¨
        for feature in features:
            self.encoder.append(self._block(in_channels, feature))
            in_channels = feature
        
        # SPPæ¨¡å—
        self.spp = SPPBlock(features[-1])
        
        # è§£ç å™¨
        for feature in reversed(features[:-1]):
            self.decoder.append(
                nn.ConvTranspose2d(in_channels, feature, kernel_size=2, stride=2)
            )
            self.decoder.append(self._block(feature * 2, feature))
            in_channels = feature
        
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)
    
    def _block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )
    
    def forward(self, x):
        skip_connections = []
        
        # ç¼–ç å™¨è·¯å¾„
        for i, down in enumerate(self.encoder):
            x = down(x)
            skip_connections.append(x)
            if i < len(self.encoder) - 1:
                x = self.pool(x)
        
        # SPPå¤„ç†
        x = self.spp(x)
        
        # è§£ç å™¨è·¯å¾„
        skip_connections = skip_connections[:-1][::-1]
        
        for idx in range(0, len(self.decoder), 2):
            x = self.decoder[idx](x)
            if idx // 2 < len(skip_connections):
                skip_connection = skip_connections[idx // 2]
                x = torch.cat((skip_connection, x), dim=1)
            x = self.decoder[idx + 1](x)
        
        return self.final_conv(x)

# ===================== æ•°æ®é›†ç±»å®šä¹‰ =====================

class MultispectralDataset(Dataset):
    """å¤šå…‰è°±å›¾åƒæ•°æ®é›†"""
    def __init__(self, clean_images, noise_type='gaussian', noise_level=25):
        self.clean_images = clean_images
        self.noise_type = noise_type
        self.noise_level = noise_level
        self.transform = transforms.Compose([
            transforms.ToTensor(),
        ])
    
    def __len__(self):
        return len(self.clean_images)
    
    def __getitem__(self, idx):
        clean_img = self.clean_images[idx]
        
        # æ·»åŠ å™ªå£°
        if self.noise_type == 'gaussian':
            noise = np.random.normal(0, self.noise_level, clean_img.shape).astype(np.float32)
            noisy_img = np.clip(clean_img.astype(np.float32) + noise, 0, 255)
        elif self.noise_type == 'salt_pepper':
            noisy_img = clean_img.copy()
            density = self.noise_level / 100.0
            h, w, c = noisy_img.shape
            salt_mask = np.random.random((h, w)) < density / 2
            pepper_mask = np.random.random((h, w)) < density / 2
            for i in range(c):
                noisy_img[salt_mask, i] = 255
                noisy_img[pepper_mask, i] = 0
        else:
            noisy_img = clean_img.copy()
        
        # è½¬æ¢ä¸ºtensor
        clean_tensor = torch.from_numpy(clean_img.transpose(2, 0, 1)).float() / 255.0
        noisy_tensor = torch.from_numpy(noisy_img.transpose(2, 0, 1)).float() / 255.0
        
        return noisy_tensor, clean_tensor

# ===================== ä¸»åº”ç”¨ç¨‹åºç±» =====================

class ImageDenoisingApp:
    def __init__(self, root):
        self.root = root
        self.root.title("å¤šå…‰è°±å›¾åƒå™ªå£°æ·»åŠ ä¸å»å™ªå¤„ç†")
        self.root.geometry("1280x800")
        
        # è®¾ç½®æ ·å¼
        self.setup_styles()
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        self.setup_chinese_font()
        
        # å›¾åƒå˜é‡
        self.original_img = None
        self.noisy_img = None
        self.denoised_img = None
        self.current_displayed = None
        
        # å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡
        self.psnr_value = tk.StringVar(value="PSNR: N/A")
        self.ssim_value = tk.StringVar(value="SSIM: N/A")
        self.mse_value = tk.StringVar(value="MSE: N/A")
        self.sam_value = tk.StringVar(value="SAM: N/A")
        
        # çº¿ç¨‹æ± ç”¨äºå¼‚æ­¥å¤„ç†
        self.executor = ThreadPoolExecutor(max_workers=2)
        
        # è¿›åº¦æ¡å˜é‡
        self.progress = tk.DoubleVar()
        
        # æ·±åº¦å­¦ä¹ æ¨¡å‹
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.ms_resnet = None
        self.dae_spp = None
        self.models_loaded = False
        
        self.setup_ui()
        
        # ç»‘å®šå¿«æ·é”®
        self.setup_shortcuts()
        
        # åˆå§‹åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹
        self.init_deep_learning_models()
    
    def setup_styles(self):
        """è®¾ç½®åº”ç”¨æ ·å¼"""
        style = ttk.Style()
        style.theme_use('clam')
        
        # è‡ªå®šä¹‰é¢œè‰²æ–¹æ¡ˆ
        style.configure('Title.TLabel', font=('Arial', 14, 'bold'))
        style.configure('Processing.TButton', font=('Arial', 10, 'bold'))
    
    def setup_chinese_font(self):
        """æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®åˆé€‚çš„ä¸­æ–‡å­—ä½“"""
        system = platform.system()
        if system == 'Windows':
            plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei']
        elif system == 'Darwin':  # macOS
            plt.rcParams['font.sans-serif'] = ['PingFang SC', 'Heiti SC']
        else:  # Linux
            plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC']
        
        plt.rcParams['axes.unicode_minus'] = False
    
    def setup_shortcuts(self):
        """è®¾ç½®é”®ç›˜å¿«æ·é”®"""
        self.root.bind('<Control-o>', lambda e: self.load_image())
        self.root.bind('<Control-s>', lambda e: self.save_image())
        self.root.bind('<Control-q>', lambda e: self.root.quit())
    
    def init_deep_learning_models(self):
        """åˆå§‹åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹"""
        try:
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            self.ms_resnet = MSResNet(in_channels=3, out_channels=3).to(self.device)
            self.dae_spp = DAE_SPP(in_channels=3, out_channels=3).to(self.device)
            
            # å°è¯•åŠ è½½é¢„è®­ç»ƒæƒé‡
            if os.path.exists('models/ms_resnet.pth'):
                self.ms_resnet.load_state_dict(torch.load('models/ms_resnet.pth', map_location=self.device))
                self.ms_resnet.eval()
            
            if os.path.exists('models/dae_spp.pth'):
                self.dae_spp.load_state_dict(torch.load('models/dae_spp.pth', map_location=self.device))
                self.dae_spp.eval()
            
            self.models_loaded = True
            self.update_status(f"æ·±åº¦å­¦ä¹ æ¨¡å‹å·²åŠ è½½ (è®¾å¤‡: {self.device})")
        except Exception as e:
            self.models_loaded = False
            self.update_status(f"æ·±åº¦å­¦ä¹ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
    
    def setup_ui(self):
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # å·¦ä¾§æ§åˆ¶é¢æ¿
        control_frame = self.create_control_panel(main_frame)
        
        # å³ä¾§å›¾åƒæ˜¾ç¤ºåŒºåŸŸ
        image_frame = self.create_image_display(main_frame)
        
        # åº•éƒ¨çŠ¶æ€æ 
        self.create_status_bar()
    
    def create_control_panel(self, parent):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        # æ§åˆ¶é¢æ¿å¤–æ¡†æ¶
        control_outer_frame = ttk.Frame(parent)
        control_outer_frame.pack(side=tk.LEFT, fill=tk.BOTH, padx=5, pady=5)
        
        # æ·»åŠ å‚ç›´æ»šåŠ¨æ¡
        v_scrollbar = Scrollbar(control_outer_frame, orient=tk.VERTICAL)
        v_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # åˆ›å»ºç”»å¸ƒç”¨äºæ»šåŠ¨
        control_canvas = tk.Canvas(control_outer_frame, yscrollcommand=v_scrollbar.set, width=300)
        control_canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        
        # é…ç½®æ»šåŠ¨æ¡
        v_scrollbar.config(command=control_canvas.yview)
        
        # åˆ›å»ºå†…éƒ¨æ¡†æ¶ç”¨äºæ”¾ç½®æ§ä»¶
        control_frame_inside = ttk.Frame(control_canvas)
        control_canvas_window = control_canvas.create_window((0, 0), window=control_frame_inside, anchor='nw')
        
        # è®¾ç½®æ§åˆ¶é¢æ¿çš„æ ‡é¢˜
        control_label = ttk.Label(control_frame_inside, text="æ§åˆ¶é¢æ¿", style='Title.TLabel')
        control_label.pack(padx=5, pady=5)
        
        # æ–‡ä»¶æ“ä½œåŒº
        self.create_file_operations(control_frame_inside)
        
        # å™ªå£°æ§åˆ¶åŒº
        self.create_noise_controls(control_frame_inside)
        
        # å»å™ªæ–¹æ³•åŒº
        self.create_denoise_controls(control_frame_inside)
        
        # æ·±åº¦å­¦ä¹ æ§åˆ¶åŒº
        self.create_deep_learning_controls(control_frame_inside)
        
        # å›¾åƒè´¨é‡è¯„ä¼°åŒº
        self.create_quality_metrics(control_frame_inside)
        
        # è¿›åº¦æ¡
        self.progress_bar = ttk.Progressbar(control_frame_inside, variable=self.progress, 
                                          maximum=100, length=250, mode='determinate')
        self.progress_bar.pack(fill=tk.X, padx=5, pady=10)
        
        # è°ƒæ•´æ§åˆ¶é¢æ¿å†…éƒ¨æ¡†æ¶å¤§å°
        control_frame_inside.update_idletasks()
        control_canvas.config(scrollregion=control_canvas.bbox("all"))
        
        # æ»šåŠ¨åŠŸèƒ½
        def _on_mousewheel(event):
            control_canvas.yview_scroll(int(-1*(event.delta/120)), "units")
        
        # åªåœ¨é¼ æ ‡æ‚¬åœåœ¨æ§åˆ¶é¢æ¿ä¸Šæ—¶å“åº”æ»šè½®
        def _on_enter(event):
            control_canvas.bind_all("<MouseWheel>", _on_mousewheel)
        
        def _on_leave(event):
            control_canvas.unbind_all("<MouseWheel>")
        
        control_canvas.bind("<Enter>", _on_enter)
        control_canvas.bind("<Leave>", _on_leave)
        
        return control_outer_frame
    
    def create_file_operations(self, parent):
        """åˆ›å»ºæ–‡ä»¶æ“ä½œåŒºåŸŸ"""
        file_frame = ttk.LabelFrame(parent, text="æ–‡ä»¶æ“ä½œ")
        file_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # åŠ è½½å›¾åƒæŒ‰é’®
        load_btn = ttk.Button(file_frame, text="åŠ è½½å›¾åƒ (Ctrl+O)", 
                             command=self.load_image, style='Processing.TButton')
        load_btn.pack(fill=tk.X, padx=5, pady=2)
        
        # ä¿å­˜æŒ‰é’®
        save_btn = ttk.Button(file_frame, text="ä¿å­˜ç»“æœ (Ctrl+S)", 
                             command=self.save_image, style='Processing.TButton')
        save_btn.pack(fill=tk.X, padx=5, pady=2)
        
        # æ‰¹é‡å¤„ç†æŒ‰é’®
        batch_btn = ttk.Button(file_frame, text="æ‰¹é‡å¤„ç†", 
                              command=self.batch_process, style='Processing.TButton')
        batch_btn.pack(fill=tk.X, padx=5, pady=2)
    
    def create_noise_controls(self, parent):
        """åˆ›å»ºå™ªå£°æ§åˆ¶åŒºåŸŸ"""
        # å™ªå£°ç±»å‹é€‰æ‹©
        noise_frame = ttk.LabelFrame(parent, text="å™ªå£°ç±»å‹")
        noise_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.noise_type = tk.StringVar(value="gaussian")
        noise_types = [
            ("é«˜æ–¯å™ªå£°", "gaussian"),
            ("æ¤’ç›å™ªå£°", "salt_pepper"),
            ("æ³Šæ¾å™ªå£°", "poisson"),
            ("æ··åˆå™ªå£°", "mixed"),
            ("åŠ¨æ€æ¨¡ç³Š", "motion_blur")
        ]
        
        for text, value in noise_types:
            ttk.Radiobutton(noise_frame, text=text, variable=self.noise_type, 
                           value=value, command=self.update_noise_params).pack(anchor=tk.W)
        
        # å™ªå£°å‚æ•°
        self.param_frame = ttk.LabelFrame(parent, text="å™ªå£°å‚æ•°")
        self.param_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # åˆå§‹åŒ–æ‰€æœ‰å‚æ•°æ§ä»¶
        self.create_all_noise_params()
        
        # æ·»åŠ å™ªå£°æŒ‰é’®
        add_noise_btn = ttk.Button(parent, text="æ·»åŠ å™ªå£°", command=self.add_noise_async,
                                  style='Processing.TButton')
        add_noise_btn.pack(fill=tk.X, padx=5, pady=5)
        
        # æ˜¾ç¤ºåˆå§‹å‚æ•°
        self.update_noise_params()
    
    def create_all_noise_params(self):
        """åˆ›å»ºæ‰€æœ‰å™ªå£°å‚æ•°æ§ä»¶"""
        # é«˜æ–¯å™ªå£°å‚æ•°
        self.gaussian_frame = ttk.Frame(self.param_frame)
        ttk.Label(self.gaussian_frame, text="æ ‡å‡†å·® (Ïƒ)").pack(anchor=tk.W)
        self.sigma_scale = Scale(self.gaussian_frame, from_=0, to=100, orient=HORIZONTAL, resolution=1)
        self.sigma_scale.set(25)
        self.sigma_scale.pack(fill=tk.X)
        self.sigma_label = ttk.Label(self.gaussian_frame, text="å½“å‰å€¼: 25")
        self.sigma_label.pack(anchor=tk.W)
        self.sigma_scale.config(command=lambda v: self.sigma_label.config(text=f"å½“å‰å€¼: {int(float(v))}"))
        
        # æ¤’ç›å™ªå£°å‚æ•°
        self.sp_frame = ttk.Frame(self.param_frame)
        ttk.Label(self.sp_frame, text="å™ªå£°å¯†åº¦").pack(anchor=tk.W)
        self.sp_scale = Scale(self.sp_frame, from_=0, to=0.5, orient=HORIZONTAL, resolution=0.01)
        self.sp_scale.set(0.05)
        self.sp_scale.pack(fill=tk.X)
        self.sp_label = ttk.Label(self.sp_frame, text="å½“å‰å€¼: 0.05")
        self.sp_label.pack(anchor=tk.W)
        self.sp_scale.config(command=lambda v: self.sp_label.config(text=f"å½“å‰å€¼: {float(v):.2f}"))
        
        # æ³Šæ¾å™ªå£°å‚æ•°
        self.poisson_frame = ttk.Frame(self.param_frame)
        ttk.Label(self.poisson_frame, text="å™ªå£°å¼ºåº¦ (Î»)").pack(anchor=tk.W)
        self.poisson_scale = Scale(self.poisson_frame, from_=1, to=50, orient=HORIZONTAL, resolution=1)
        self.poisson_scale.set(10)
        self.poisson_scale.pack(fill=tk.X)
        self.poisson_label = ttk.Label(self.poisson_frame, text="å½“å‰å€¼: 10")
        self.poisson_label.pack(anchor=tk.W)
        self.poisson_scale.config(command=lambda v: self.poisson_label.config(text=f"å½“å‰å€¼: {int(float(v))}"))
        
        # åŠ¨æ€æ¨¡ç³Šå‚æ•°
        self.blur_frame = ttk.Frame(self.param_frame)
        ttk.Label(self.blur_frame, text="æ¨¡ç³Šé•¿åº¦").pack(anchor=tk.W)
        self.blur_length_scale = Scale(self.blur_frame, from_=1, to=20, orient=HORIZONTAL, resolution=1)
        self.blur_length_scale.set(5)
        self.blur_length_scale.pack(fill=tk.X)
        ttk.Label(self.blur_frame, text="æ¨¡ç³Šè§’åº¦").pack(anchor=tk.W)
        self.blur_angle_scale = Scale(self.blur_frame, from_=0, to=180, orient=HORIZONTAL, resolution=1)
        self.blur_angle_scale.set(45)
        self.blur_angle_scale.pack(fill=tk.X)
    
    def update_noise_params(self):
        """æ ¹æ®é€‰æ‹©çš„å™ªå£°ç±»å‹æ›´æ–°å‚æ•°æ˜¾ç¤º"""
        # éšè—æ‰€æœ‰å‚æ•°æ¡†æ¶
        for frame in [self.gaussian_frame, self.sp_frame, self.poisson_frame, self.blur_frame]:
            frame.pack_forget()
        
        # æ˜¾ç¤ºå¯¹åº”çš„å‚æ•°æ¡†æ¶
        noise_type = self.noise_type.get()
        if noise_type == "gaussian":
            self.gaussian_frame.pack(fill=tk.X, padx=5, pady=5)
        elif noise_type == "salt_pepper":
            self.sp_frame.pack(fill=tk.X, padx=5, pady=5)
        elif noise_type == "poisson":
            self.poisson_frame.pack(fill=tk.X, padx=5, pady=5)
        elif noise_type == "motion_blur":
            self.blur_frame.pack(fill=tk.X, padx=5, pady=5)
        elif noise_type == "mixed":
            self.gaussian_frame.pack(fill=tk.X, padx=5, pady=5)
            self.sp_frame.pack(fill=tk.X, padx=5, pady=5)
    
    def create_denoise_controls(self, parent):
        """åˆ›å»ºå»å™ªæ§åˆ¶åŒºåŸŸ"""
        denoise_frame = ttk.LabelFrame(parent, text="ä¼ ç»Ÿå»å™ªæ–¹æ³•")
        denoise_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # å»å™ªå‚æ•°æ ‡ç­¾é¡µ
        notebook = ttk.Notebook(denoise_frame)
        notebook.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # å‡å€¼æ»¤æ³¢å‚æ•°
        mean_tab = ttk.Frame(notebook)
        notebook.add(mean_tab, text="å‡å€¼æ»¤æ³¢")
        ttk.Label(mean_tab, text="çª—å£å¤§å°").pack(anchor=tk.W, padx=5, pady=2)
        self.mean_size = tk.IntVar(value=5)
        for size in [3, 5, 7, 9]:
            ttk.Radiobutton(mean_tab, text=f"{size}x{size}", variable=self.mean_size, 
                           value=size).pack(anchor=tk.W, padx=10)
        
        # ä¸­å€¼æ»¤æ³¢å‚æ•°
        median_tab = ttk.Frame(notebook)
        notebook.add(median_tab, text="ä¸­å€¼æ»¤æ³¢")
        ttk.Label(median_tab, text="çª—å£å¤§å°").pack(anchor=tk.W, padx=5, pady=2)
        self.median_size = tk.IntVar(value=5)
        for size in [3, 5, 7, 9]:
            ttk.Radiobutton(median_tab, text=f"{size}x{size}", variable=self.median_size, 
                           value=size).pack(anchor=tk.W, padx=10)
        
        # å°æ³¢å˜æ¢å‚æ•°
        wavelet_tab = ttk.Frame(notebook)
        notebook.add(wavelet_tab, text="å°æ³¢å˜æ¢")
        
        ttk.Label(wavelet_tab, text="å°æ³¢åŸº").pack(anchor=tk.W, padx=5, pady=2)
        self.wavelet_base = tk.StringVar(value="db4")
        bases = ["db1", "db2", "db4", "db8", "haar", "sym2", "sym4", "coif1", "bior1.3"]
        wavelet_combo = ttk.Combobox(wavelet_tab, textvariable=self.wavelet_base, values=bases, width=15)
        wavelet_combo.pack(fill=tk.X, padx=10, pady=2)
        
        ttk.Label(wavelet_tab, text="åˆ†è§£å±‚æ•°").pack(anchor=tk.W, padx=5, pady=2)
        self.wavelet_level = tk.IntVar(value=3)
        for level in range(2, 6):
            ttk.Radiobutton(wavelet_tab, text=f"{level}å±‚", variable=self.wavelet_level, 
                           value=level).pack(anchor=tk.W, padx=10)
        
        ttk.Label(wavelet_tab, text="é˜ˆå€¼æ¨¡å¼").pack(anchor=tk.W, padx=5, pady=2)
        self.wavelet_mode = tk.StringVar(value="soft")
        ttk.Radiobutton(wavelet_tab, text="è½¯é˜ˆå€¼", variable=self.wavelet_mode, 
                       value="soft").pack(anchor=tk.W, padx=10)
        ttk.Radiobutton(wavelet_tab, text="ç¡¬é˜ˆå€¼", variable=self.wavelet_mode, 
                       value="hard").pack(anchor=tk.W, padx=10)
        
        # æ‰§è¡Œå»å™ªæŒ‰é’®
        button_frame = ttk.Frame(parent)
        button_frame.pack(fill=tk.X, padx=5, pady=10)
        
        # ä½¿ç”¨ä¸åŒçš„é¢œè‰²å’Œå›¾æ ‡ï¼ˆé€šè¿‡Unicodeå­—ç¬¦ï¼‰
        mean_btn = tk.Button(button_frame, text="â–¶ å‡å€¼æ»¤æ³¢å»å™ª", bg="#e1f5fe", 
                            font=("Arial", 10, "bold"), command=lambda: self.denoise_async("mean"))
        mean_btn.pack(fill=tk.X, pady=2)
        
        median_btn = tk.Button(button_frame, text="â–¶ ä¸­å€¼æ»¤æ³¢å»å™ª", bg="#e8f5e9", 
                              font=("Arial", 10, "bold"), command=lambda: self.denoise_async("median"))
        median_btn.pack(fill=tk.X, pady=2)
        
        wavelet_btn = tk.Button(button_frame, text="â–¶ å°æ³¢å˜æ¢å»å™ª", bg="#fff3e0", 
                               font=("Arial", 10, "bold"), command=lambda: self.denoise_async("wavelet"))
        wavelet_btn.pack(fill=tk.X, pady=2)
    
    def create_deep_learning_controls(self, parent):
        """åˆ›å»ºæ·±åº¦å­¦ä¹ æ§åˆ¶åŒºåŸŸ"""
        dl_frame = ttk.LabelFrame(parent, text="æ·±åº¦å­¦ä¹ å»å™ªæ–¹æ³•")
        dl_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # æ¨¡å‹çŠ¶æ€æ˜¾ç¤º
        self.model_status_label = ttk.Label(dl_frame, text="æ¨¡å‹çŠ¶æ€: æ£€æŸ¥ä¸­...")
        self.model_status_label.pack(padx=5, pady=5)
        
        # æ·±åº¦å­¦ä¹ å»å™ªæŒ‰é’®
        msresnet_btn = tk.Button(dl_frame, text="ğŸ§  MS-ResNetå»å™ª", bg="#e3f2fd", 
                                font=("Arial", 10, "bold"), 
                                command=lambda: self.denoise_deep_learning_async("ms_resnet"))
        msresnet_btn.pack(fill=tk.X, padx=5, pady=2)
        
        dae_btn = tk.Button(dl_frame, text="ğŸ§  DAE-SPPå»å™ª", bg="#f3e5f5", 
                           font=("Arial", 10, "bold"), 
                           command=lambda: self.denoise_deep_learning_async("dae_spp"))
        dae_btn.pack(fill=tk.X, padx=5, pady=2)
        
        # æ¯”è¾ƒæ‰€æœ‰æ–¹æ³•æŒ‰é’®
        compare_btn = tk.Button(dl_frame, text="âš¡ æ¯”è¾ƒæ‰€æœ‰æ–¹æ³•", bg="#fce4ec", 
                               font=("Arial", 10, "bold"), command=self.compare_all_methods)
        compare_btn.pack(fill=tk.X, padx=5, pady=5)
        
        # è®­ç»ƒæŒ‰é’®ï¼ˆå¯é€‰ï¼‰
        train_frame = ttk.Frame(dl_frame)
        train_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(train_frame, text="æ¨¡å‹è®­ç»ƒï¼ˆéœ€è¦æ•°æ®é›†ï¼‰").pack(anchor=tk.W)
        train_btn = ttk.Button(train_frame, text="è®­ç»ƒæ¨¡å‹", command=self.train_models)
        train_btn.pack(fill=tk.X, pady=2)
        
        # æ›´æ–°æ¨¡å‹çŠ¶æ€
        self.update_model_status()
    
    def update_model_status(self):
        """æ›´æ–°æ¨¡å‹çŠ¶æ€æ˜¾ç¤º"""
        if self.models_loaded:
            self.model_status_label.config(text=f"æ¨¡å‹çŠ¶æ€: å·²åŠ è½½ (è®¾å¤‡: {self.device})")
        else:
            self.model_status_label.config(text="æ¨¡å‹çŠ¶æ€: æœªåŠ è½½")
    
    def create_quality_metrics(self, parent):
        """åˆ›å»ºå›¾åƒè´¨é‡è¯„ä¼°åŒºåŸŸ"""
        quality_frame = ttk.LabelFrame(parent, text="å›¾åƒè´¨é‡è¯„ä¼°")
        quality_frame.pack(fill=tk.X, padx=5, pady=5)
        
        # ä½¿ç”¨ç½‘æ ¼å¸ƒå±€æ˜¾ç¤ºæŒ‡æ ‡
        metrics_frame = ttk.Frame(quality_frame)
        metrics_frame.pack(fill=tk.X, padx=5, pady=5)
        
        ttk.Label(metrics_frame, textvariable=self.psnr_value).grid(row=0, column=0, sticky=tk.W, padx=5)
        ttk.Label(metrics_frame, textvariable=self.ssim_value).grid(row=1, column=0, sticky=tk.W, padx=5)
        ttk.Label(metrics_frame, textvariable=self.mse_value).grid(row=2, column=0, sticky=tk.W, padx=5)
        ttk.Label(metrics_frame, textvariable=self.sam_value).grid(row=3, column=0, sticky=tk.W, padx=5)
        
        # æ·»åŠ å¸®åŠ©ä¿¡æ¯
        help_text = "PSNR: è¶Šé«˜è¶Šå¥½ (>30dB è‰¯å¥½)\nSSIM: è¶Šæ¥è¿‘1è¶Šå¥½\nMSE: è¶Šä½è¶Šå¥½\nSAM: è¶Šä½è¶Šå¥½ (å¼§åº¦)"
        help_label = ttk.Label(metrics_frame, text=help_text, font=("Arial", 8), foreground="gray")
        help_label.grid(row=0, column=1, rowspan=4, padx=10, sticky=tk.W)
    
    def create_image_display(self, parent):
        """åˆ›å»ºå›¾åƒæ˜¾ç¤ºåŒºåŸŸ"""
        image_frame = ttk.LabelFrame(parent, text="å›¾åƒæ˜¾ç¤º")
        image_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # åˆ›å»ºå·¥å…·æ 
        toolbar_frame = ttk.Frame(image_frame)
        toolbar_frame.pack(fill=tk.X, padx=5, pady=2)
        
        # è§†å›¾é€‰æ‹©æŒ‰é’®
        ttk.Button(toolbar_frame, text="2x2è§†å›¾", 
                  command=lambda: self.change_view_layout("2x2")).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar_frame, text="1x3è§†å›¾", 
                  command=lambda: self.change_view_layout("1x3")).pack(side=tk.LEFT, padx=2)
        ttk.Button(toolbar_frame, text="å•å›¾è§†å›¾", 
                  command=lambda: self.change_view_layout("single")).pack(side=tk.LEFT, padx=2)
        
        # åˆ›å»ºæ˜¾ç¤ºåŒº
        self.fig = plt.Figure(figsize=(10, 8))
        self.canvas = FigureCanvasTkAgg(self.fig, master=image_frame)
        self.canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # åˆå§‹åŒ–å­å›¾
        self.current_layout = "2x2"
        self.setup_subplots()
        
        return image_frame
    
    def create_status_bar(self):
        """åˆ›å»ºçŠ¶æ€æ """
        status_frame = ttk.Frame(self.root)
        status_frame.pack(fill=tk.X, side=tk.BOTTOM)
        
        self.status_label = ttk.Label(status_frame, text="å°±ç»ª", relief=tk.SUNKEN)
        self.status_label.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        # å›¾åƒä¿¡æ¯æ ‡ç­¾
        self.image_info_label = ttk.Label(status_frame, text="", relief=tk.SUNKEN)
        self.image_info_label.pack(side=tk.RIGHT, padx=5)
    
    def change_view_layout(self, layout):
        """æ”¹å˜è§†å›¾å¸ƒå±€"""
        self.current_layout = layout
        self.setup_subplots()
        self.refresh_display()
    
    def setup_subplots(self):
        """æ ¹æ®å½“å‰å¸ƒå±€è®¾ç½®å­å›¾"""
        self.fig.clear()
        
        if self.current_layout == "2x2":
            # åˆ›å»º2x2çš„å­å›¾å¸ƒå±€
            self.ax1 = self.fig.add_subplot(221)
            self.ax2 = self.fig.add_subplot(222)
            self.ax3 = self.fig.add_subplot(223)
            self.ax4 = self.fig.add_subplot(224)
            
            self.ax1.set_title("åŸå§‹å›¾åƒ")
            self.ax2.set_title("å«å™ªå›¾åƒ")
            self.ax3.set_title("å»å™ªç»“æœ")
            self.ax4.set_title("å›¾åƒå¯¹æ¯”")
            
            self.axes = [self.ax1, self.ax2, self.ax3, self.ax4]
            
        elif self.current_layout == "1x3":
            # åˆ›å»º1x3çš„å­å›¾å¸ƒå±€
            self.ax1 = self.fig.add_subplot(131)
            self.ax2 = self.fig.add_subplot(132)
            self.ax3 = self.fig.add_subplot(133)
            
            self.ax1.set_title("åŸå§‹å›¾åƒ")
            self.ax2.set_title("å«å™ªå›¾åƒ")
            self.ax3.set_title("å»å™ªç»“æœ")
            
            self.axes = [self.ax1, self.ax2, self.ax3]
            
        elif self.current_layout == "single":
            # å•å›¾è§†å›¾
            self.ax1 = self.fig.add_subplot(111)
            self.ax1.set_title("å›¾åƒæ˜¾ç¤º")
            self.axes = [self.ax1]
        
        for ax in self.axes:
            ax.axis('off')
        
        self.fig.tight_layout()
        self.canvas.draw()
    
    def refresh_display(self):
        """åˆ·æ–°æ˜¾ç¤ºå†…å®¹"""
        # æ¸…é™¤æ‰€æœ‰å­å›¾
        for ax in self.axes:
            ax.clear()
            ax.axis('off')
        
        # æ ¹æ®å½“å‰å¸ƒå±€é‡æ–°æ˜¾ç¤ºå›¾åƒ
        if self.current_layout in ["2x2", "1x3"]:
            if self.original_img is not None:
                img_rgb = cv2.cvtColor(self.original_img, cv2.COLOR_BGR2RGB)
                self.ax1.imshow(img_rgb)
                self.ax1.set_title("åŸå§‹å›¾åƒ")
            
            if self.noisy_img is not None and len(self.axes) > 1:
                noisy_rgb = cv2.cvtColor(self.noisy_img, cv2.COLOR_BGR2RGB)
                self.ax2.imshow(noisy_rgb)
                self.ax2.set_title("å«å™ªå›¾åƒ")
            
            if self.denoised_img is not None and len(self.axes) > 2:
                denoised_rgb = cv2.cvtColor(self.denoised_img, cv2.COLOR_BGR2RGB)
                self.ax3.imshow(denoised_rgb)
                self.ax3.set_title("å»å™ªç»“æœ")
            
            if self.current_layout == "2x2" and len(self.axes) > 3:
                # æ˜¾ç¤ºå¯¹æ¯”å›¾
                if self.noisy_img is not None and self.denoised_img is not None:
                    noisy_rgb = cv2.cvtColor(self.noisy_img, cv2.COLOR_BGR2RGB)
                    denoised_rgb = cv2.cvtColor(self.denoised_img, cv2.COLOR_BGR2RGB)
                    compared = np.hstack((noisy_rgb, denoised_rgb))
                    self.ax4.imshow(compared)
                    self.ax4.set_title("å›¾åƒå¯¹æ¯”ï¼ˆå«å™ª vs å»å™ªï¼‰")
        
        self.canvas.draw()
    
    def load_image(self):
        """åŠ è½½å›¾åƒ"""
        file_path = filedialog.askopenfilename(
            filetypes=[("å›¾åƒæ–‡ä»¶", "*.jpg *.jpeg *.png *.bmp *.tif *.tiff")]
        )
        if file_path:
            try:
                self.original_img = cv2.imread(file_path)
                if self.original_img is None:
                    messagebox.showerror("é”™è¯¯", "æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶ï¼")
                    return
                
                # æ›´æ–°å›¾åƒä¿¡æ¯
                h, w, c = self.original_img.shape
                self.image_info_label.config(text=f"å›¾åƒ: {w}x{h}, {c}é€šé“")
                
                # è½¬æ¢BGRåˆ°RGBç”¨äºæ˜¾ç¤º
                img_rgb = cv2.cvtColor(self.original_img, cv2.COLOR_BGR2RGB)
                self.display_image(self.ax1, img_rgb, "åŸå§‹å›¾åƒ")
                
                # æ¸…é™¤å…¶ä»–å›¾åƒ
                self.noisy_img = None
                self.denoised_img = None
                
                # åˆ·æ–°æ˜¾ç¤º
                self.refresh_display()
                
                # é‡ç½®è¯„ä¼°æŒ‡æ ‡
                self.reset_metrics()
                
                # æ›´æ–°çŠ¶æ€
                self.update_status(f"å·²åŠ è½½å›¾åƒ: {os.path.basename(file_path)}")
                
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"åŠ è½½å›¾åƒæ—¶å‡ºé”™: {str(e)}")
    
    def add_noise_async(self):
        """å¼‚æ­¥æ·»åŠ å™ªå£°"""
        if self.original_img is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆåŠ è½½å›¾åƒï¼")
            return
        
        self.update_status("æ­£åœ¨æ·»åŠ å™ªå£°...")
        self.progress.set(0)
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        self.executor.submit(self.add_noise_worker)
    
    def add_noise_worker(self):
        """å™ªå£°æ·»åŠ å·¥ä½œçº¿ç¨‹"""
        try:
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(20))
            
            # åˆ›å»ºå™ªå£°å›¾åƒçš„å‰¯æœ¬
            self.noisy_img = self.original_img.copy()
            
            noise_type = self.noise_type.get()
            
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(50))
            
            if noise_type == "gaussian":
                self.add_gaussian_noise()
            elif noise_type == "salt_pepper":
                self.add_salt_pepper_noise()
            elif noise_type == "poisson":
                self.add_poisson_noise()
            elif noise_type == "mixed":
                self.add_mixed_noise()
            elif noise_type == "motion_blur":
                self.add_motion_blur()
            
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(80))
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self.update_noise_display)
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æ·»åŠ å™ªå£°æ—¶å‡ºé”™: {str(e)}"))
        finally:
            self.root.after(0, lambda: self.progress.set(100))
            self.root.after(500, lambda: self.progress.set(0))
    
    def add_gaussian_noise(self):
        """æ·»åŠ é«˜æ–¯å™ªå£°"""
        sigma = self.sigma_scale.get()
        gauss = np.random.normal(0, sigma, self.noisy_img.shape).astype(np.float32)
        self.noisy_img = np.clip(self.noisy_img + gauss, 0, 255).astype(np.uint8)
    
    def add_salt_pepper_noise(self):
        """æ·»åŠ æ¤’ç›å™ªå£°"""
        density = self.sp_scale.get()
        h, w, c = self.noisy_img.shape
        
        # ä¸ºæ¤’å™ªå£°å’Œç›å™ªå£°åˆ†åˆ«ç”Ÿæˆéšæœºæ©ç 
        salt_mask = np.random.random((h, w)) < density / 2
        pepper_mask = np.random.random((h, w)) < density / 2
        
        for i in range(c):
            self.noisy_img[salt_mask, i] = 255
            self.noisy_img[pepper_mask, i] = 0
    
    def add_poisson_noise(self):
        """æ·»åŠ æ³Šæ¾å™ªå£°"""
        lam = self.poisson_scale.get()
        norm_img = self.noisy_img / 255.0
        noisy_norm = np.random.poisson(norm_img * lam) / lam
        self.noisy_img = np.clip(noisy_norm * 255, 0, 255).astype(np.uint8)
    
    def add_mixed_noise(self):
        """æ·»åŠ æ··åˆå™ªå£°"""
        # å…ˆæ·»åŠ é«˜æ–¯å™ªå£°
        self.add_gaussian_noise()
        
        # å†æ·»åŠ æ¤’ç›å™ªå£°ï¼ˆå¯†åº¦å‡åŠï¼‰
        original_density = self.sp_scale.get()
        self.sp_scale.set(original_density / 2)
        self.add_salt_pepper_noise()
        self.sp_scale.set(original_density)  # æ¢å¤åŸå€¼
    
    def add_motion_blur(self):
        """æ·»åŠ åŠ¨æ€æ¨¡ç³Š"""
        length = self.blur_length_scale.get()
        angle = self.blur_angle_scale.get()
        
        # åˆ›å»ºè¿åŠ¨æ¨¡ç³Šæ ¸
        kernel = self.create_motion_blur_kernel(length, angle)
        
        # åº”ç”¨å·ç§¯
        for i in range(3):
            self.noisy_img[:,:,i] = cv2.filter2D(self.noisy_img[:,:,i], -1, kernel)
    
    @lru_cache(maxsize=32)
    def create_motion_blur_kernel(self, length, angle):
        """åˆ›å»ºè¿åŠ¨æ¨¡ç³Šæ ¸ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        rad = np.deg2rad(angle)
        dx = np.cos(rad)
        dy = np.sin(rad)
        kernel_size = 2 * length + 1
        kernel = np.zeros((kernel_size, kernel_size))
        
        cx, cy = length, length
        for i in range(kernel_size):
            x = int(cx + dx * (i - length))
            y = int(cy + dy * (i - length))
            if 0 <= x < kernel_size and 0 <= y < kernel_size:
                kernel[y, x] = 1
        
        return kernel / np.sum(kernel)
    
    def update_noise_display(self):
        """æ›´æ–°å™ªå£°å›¾åƒæ˜¾ç¤º"""
        noisy_rgb = cv2.cvtColor(self.noisy_img, cv2.COLOR_BGR2RGB)
        self.display_image(self.ax2, noisy_rgb, "å«å™ªå›¾åƒ")
        
        # åˆ·æ–°æ˜¾ç¤º
        self.refresh_display()
        
        # é‡ç½®è¯„ä¼°æŒ‡æ ‡
        self.reset_metrics()
        
        self.update_status("å™ªå£°æ·»åŠ å®Œæˆ")
    
    def denoise_async(self, method):
        """å¼‚æ­¥å»å™ªå¤„ç†"""
        if self.noisy_img is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆæ·»åŠ å™ªå£°ï¼")
            return
        
        self.update_status(f"æ­£åœ¨è¿›è¡Œ{method}å»å™ª...")
        self.progress.set(0)
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        self.executor.submit(self.denoise_worker, method)
    
    def denoise_worker(self, method):
        """å»å™ªå·¥ä½œçº¿ç¨‹"""
        try:
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(30))
            
            if method == "mean":
                kernel_size = self.mean_size.get()
                self.denoised_img = cv2.blur(self.noisy_img, (kernel_size, kernel_size))
                title = f"å‡å€¼æ»¤æ³¢ ({kernel_size}x{kernel_size})"
                
            elif method == "median":
                kernel_size = self.median_size.get()
                self.denoised_img = cv2.medianBlur(self.noisy_img, kernel_size)
                title = f"ä¸­å€¼æ»¤æ³¢ ({kernel_size}x{kernel_size})"
                
            elif method == "wavelet":
                wavelet = self.wavelet_base.get()
                level = self.wavelet_level.get()
                mode = self.wavelet_mode.get()
                
                self.root.after(0, lambda: self.progress.set(50))
                
                self.denoised_img = self.wavelet_denoise_color(
                    self.noisy_img, wavelet=wavelet, level=level, mode=mode
                )
                title = f"å°æ³¢å˜æ¢å»å™ª ({wavelet}, {level}å±‚, {mode}é˜ˆå€¼)"
            
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(80))
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, lambda: self.update_denoise_display(title))
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"å»å™ªå¤„ç†æ—¶å‡ºé”™: {str(e)}"))
        finally:
            self.root.after(0, lambda: self.progress.set(100))
            self.root.after(500, lambda: self.progress.set(0))
    
    def denoise_deep_learning_async(self, model_name):
        """å¼‚æ­¥æ·±åº¦å­¦ä¹ å»å™ªå¤„ç†"""
        if self.noisy_img is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆæ·»åŠ å™ªå£°ï¼")
            return
        
        if not self.models_loaded:
            messagebox.showwarning("æç¤º", "æ·±åº¦å­¦ä¹ æ¨¡å‹æœªåŠ è½½ï¼")
            return
        
        self.update_status(f"æ­£åœ¨è¿›è¡Œ{model_name}å»å™ª...")
        self.progress.set(0)
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œ
        self.executor.submit(self.denoise_deep_learning_worker, model_name)
    
    def denoise_deep_learning_worker(self, model_name):
        """æ·±åº¦å­¦ä¹ å»å™ªå·¥ä½œçº¿ç¨‹"""
        try:
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(20))
            
            # é¢„å¤„ç†å›¾åƒ
            noisy_tensor = torch.from_numpy(
                self.noisy_img.transpose(2, 0, 1)
            ).float().unsqueeze(0) / 255.0
            noisy_tensor = noisy_tensor.to(self.device)
            
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(50))
            
            # é€‰æ‹©æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†
            with torch.no_grad():
                if model_name == "ms_resnet":
                    denoised_tensor = self.ms_resnet(noisy_tensor)
                    title = "MS-ResNetå»å™ª"
                elif model_name == "dae_spp":
                    denoised_tensor = self.dae_spp(noisy_tensor)
                    title = "DAE-SPPå»å™ª"
                else:
                    raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹: {model_name}")
            
            # æ›´æ–°è¿›åº¦
            self.root.after(0, lambda: self.progress.set(80))
            
            # åå¤„ç†
            denoised_numpy = denoised_tensor.squeeze(0).cpu().numpy()
            denoised_numpy = np.transpose(denoised_numpy, (1, 2, 0))
            self.denoised_img = np.clip(denoised_numpy * 255, 0, 255).astype(np.uint8)
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, lambda: self.update_denoise_display(title))
            
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("é”™è¯¯", f"æ·±åº¦å­¦ä¹ å»å™ªæ—¶å‡ºé”™: {str(e)}"))
        finally:
            self.root.after(0, lambda: self.progress.set(100))
            self.root.after(500, lambda: self.progress.set(0))
    
    def update_denoise_display(self, title):
        """æ›´æ–°å»å™ªç»“æœæ˜¾ç¤º"""
        denoised_rgb = cv2.cvtColor(self.denoised_img, cv2.COLOR_BGR2RGB)
        self.display_image(self.ax3, denoised_rgb, title)
        
        # åˆ·æ–°æ˜¾ç¤º
        self.refresh_display()
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        self.calculate_metrics()
        
        self.update_status("å»å™ªå¤„ç†å®Œæˆ")
    
    def compare_all_methods(self):
        """æ¯”è¾ƒæ‰€æœ‰å»å™ªæ–¹æ³•"""
        if self.noisy_img is None:
            messagebox.showwarning("æç¤º", "è¯·å…ˆæ·»åŠ å™ªå£°ï¼")
            return
        
        # åˆ›å»ºæ¯”è¾ƒçª—å£
        compare_window = tk.Toplevel(self.root)
        compare_window.title("å»å™ªæ–¹æ³•æ¯”è¾ƒ")
        compare_window.geometry("1400x900")
        
        # åˆ›å»ºå›¾å½¢
        fig = plt.Figure(figsize=(14, 9))
        canvas = FigureCanvasTkAgg(fig, master=compare_window)
        canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
        
        # æ‰§è¡Œæ‰€æœ‰å»å™ªæ–¹æ³•
        methods = [
            ("åŸå§‹å›¾åƒ", self.original_img),
            ("å«å™ªå›¾åƒ", self.noisy_img),
            (f"å‡å€¼æ»¤æ³¢({self.mean_size.get()}x{self.mean_size.get()})", 
             cv2.blur(self.noisy_img, (self.mean_size.get(), self.mean_size.get()))),
            (f"ä¸­å€¼æ»¤æ³¢({self.median_size.get()}x{self.median_size.get()})", 
             cv2.medianBlur(self.noisy_img, self.median_size.get())),
            (f"å°æ³¢å˜æ¢({self.wavelet_base.get()})", 
             self.wavelet_denoise_color(self.noisy_img, self.wavelet_base.get(), 
                                       self.wavelet_level.get(), self.wavelet_mode.get()))
        ]
        
        # æ·»åŠ æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚æœå·²åŠ è½½ï¼‰
        if self.models_loaded:
            # MS-ResNet
            noisy_tensor = torch.from_numpy(
                self.noisy_img.transpose(2, 0, 1)
            ).float().unsqueeze(0) / 255.0
            noisy_tensor = noisy_tensor.to(self.device)
            
            with torch.no_grad():
                # MS-ResNetå»å™ª
                ms_resnet_out = self.ms_resnet(noisy_tensor)
                ms_resnet_img = ms_resnet_out.squeeze(0).cpu().numpy()
                ms_resnet_img = np.transpose(ms_resnet_img, (1, 2, 0))
                ms_resnet_img = np.clip(ms_resnet_img * 255, 0, 255).astype(np.uint8)
                methods.append(("MS-ResNet", ms_resnet_img))
                
                # DAE-SPPå»å™ª
                dae_spp_out = self.dae_spp(noisy_tensor)
                dae_spp_img = dae_spp_out.squeeze(0).cpu().numpy()
                dae_spp_img = np.transpose(dae_spp_img, (1, 2, 0))
                dae_spp_img = np.clip(dae_spp_img * 255, 0, 255).astype(np.uint8)
                methods.append(("DAE-SPP", dae_spp_img))
        
        # åˆ›å»ºå­å›¾
        rows = 3
        cols = 3
        for i, (title, img) in enumerate(methods):
            if i < rows * cols:
                ax = fig.add_subplot(rows, cols, i+1)
                if img is not None:
                    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    ax.imshow(img_rgb)
                    
                    # è®¡ç®—PSNRå’ŒSSIMï¼ˆé™¤äº†åŸå§‹å›¾åƒï¼‰
                    if i > 0 and self.original_img is not None:
                        psnr = self.calculate_psnr(self.original_img, img)
                        ssim_val = self.calculate_ssim(
                            cv2.cvtColor(self.original_img, cv2.COLOR_BGR2GRAY),
                            cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                        )
                        sam = self.calculate_sam(self.original_img, img)
                        ax.set_title(f"{title}\nPSNR: {psnr:.2f} dB, SSIM: {ssim_val:.3f}\nSAM: {sam:.4f} rad", fontsize=9)
                    else:
                        ax.set_title(title)
                
                ax.axis('off')
        
        fig.tight_layout()
        canvas.draw()
    
    def calculate_metrics(self):
        """è®¡ç®—å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡"""
        if self.original_img is not None and self.denoised_img is not None:
            # è®¡ç®—PSNR
            psnr = self.calculate_psnr(self.original_img, self.denoised_img)
            self.psnr_value.set(f"PSNR: {psnr:.2f} dB")
            
            # è®¡ç®—SSIM
            original_gray = cv2.cvtColor(self.original_img, cv2.COLOR_BGR2GRAY)
            denoised_gray = cv2.cvtColor(self.denoised_img, cv2.COLOR_BGR2GRAY)
            ssim_val = self.calculate_ssim(original_gray, denoised_gray)
            self.ssim_value.set(f"SSIM: {ssim_val:.4f}")
            
            # è®¡ç®—MSE
            mse = np.mean((self.original_img.astype(np.float32) - 
                          self.denoised_img.astype(np.float32)) ** 2)
            self.mse_value.set(f"MSE: {mse:.2f}")
            
            # è®¡ç®—SAM
            sam = self.calculate_sam(self.original_img, self.denoised_img)
            self.sam_value.set(f"SAM: {sam:.4f} rad")
    
    def calculate_psnr(self, original, denoised):
        """è®¡ç®—PSNR"""
        if original.shape != denoised.shape:
            denoised = cv2.resize(denoised, (original.shape[1], original.shape[0]))
        
        mse = np.mean((original.astype(np.float32) - denoised.astype(np.float32)) ** 2)
        if mse == 0:
            return 100
        
        max_pixel = 255.0
        psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
        return psnr
    
    def calculate_ssim(self, img1, img2, window_size=11, k1=0.01, k2=0.03, L=255):
        """è®¡ç®—SSIMï¼ˆç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼‰"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # ä½¿ç”¨skimageçš„SSIMå®ç°
        return ssim(img1, img2, data_range=L)
    
    def calculate_sam(self, img1, img2):
        """è®¡ç®—å…‰è°±è§’æ˜ å°„ï¼ˆSAMï¼‰"""
        if img1.shape != img2.shape:
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))
        
        # å°†å›¾åƒå±•å¹³ä¸ºå‘é‡
        img1_flat = img1.reshape(-1, img1.shape[2])
        img2_flat = img2.reshape(-1, img2.shape[2])
        
        # è®¡ç®—æ¯ä¸ªåƒç´ çš„å…‰è°±è§’
        dots = np.sum(img1_flat * img2_flat, axis=1)
        norms1 = np.linalg.norm(img1_flat, axis=1)
        norms2 = np.linalg.norm(img2_flat, axis=1)
        
        # é¿å…é™¤é›¶
        norms = norms1 * norms2
        norms[norms == 0] = 1e-8
        
        # è®¡ç®—è§’åº¦
        cos_angles = np.clip(dots / norms, -1, 1)
        angles = np.arccos(cos_angles)
        
        # è¿”å›å¹³å‡å…‰è°±è§’
        return np.mean(angles)